<!DOCTYPE html>
<html lang="en">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/avatar.png">
  <link rel="icon" type="image/png" href="/img/avatar.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="description" content=" keywords: author: Miki language: zh-CN timezone: ">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  <title>明天会下雨吗？ ~ Miki&#39;s blog</title>

  <link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"  >
<link rel="stylesheet" href="/lib/bootstrap/css/bootstrap.min.css"  >
<link rel="stylesheet" href="/lib/mdbootstrap/css/mdb.min.css"  >
<link rel="stylesheet" href="/lib/github-markdown/github-markdown.min.css"  >

<link rel="stylesheet" href="//at.alicdn.com/t/font_1067060_qzomjdt8bmp.css">



  <link rel="stylesheet" href="/lib/prettify/tomorrow-night-eighties.min.css"  >

<link rel="stylesheet" href="/css/main.css"  >


  <link rel="stylesheet" href="/lib/fancybox/jquery.fancybox.min.css"  >


<meta name="generator" content="Hexo 4.2.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Miki's blog</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">首页</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">分类</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">标签</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">关于</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" false
         style="background: url('/img/default.png')no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask rgba-black-light flex-center">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              <br>
              
                <p class="mt-3">
                  <i class="fas fa-calendar-alt" aria-hidden="true"></i>&nbsp;
                  Monday, March 30th 2020, 11:25 am
                </p>
              

              <p>
                
                  
                  &nbsp;<i class="far fa-chart-bar"></i>
                  <span class="post-count">
                    6.3k 字
                  </span>&nbsp;
                

                
                  
                  &nbsp;<i class="far fa-clock"></i>
                  <span class="post-count">
                      24 分钟
                  </span>&nbsp;
                

                
                  <!-- 不蒜子统计文章PV -->
                  
                  &nbsp;<i class="far fa-eye" aria-hidden="true"></i>&nbsp;
                  <span id="busuanzi_container_page_pv">
                    <span id="busuanzi_value_page_pv"></span> 次
                  </span>&nbsp;
                
              </p>
            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="py-5 z-depth-3" id="board">
        <div class="post-content mx-auto" id="post">
          <div class="markdown-body">
            <p>[TOC]</p>
<h1 id="数据预处理"><a class="markdownIt-Anchor" href="#数据预处理"></a> 数据预处理</h1>
<h2 id="svmsvcsvr的区别"><a class="markdownIt-Anchor" href="#svmsvcsvr的区别"></a> SVM,SVC,SVR的区别</h2>
<p>SVM是一个大类，其中的SVC是用来分类的，SVR是用来做回归分析的</p>
<ul>
<li>SVM=Support Vector Machine 是支持向量</li>
<li>SVC=Support Vector Classification就是支持向量机用于分类</li>
<li>SVR=Support Vector Regression.就是支持向量机用于回归分析</li>
</ul>
<p><strong>SVM一般用在</strong>处理二分类问题中，这样效果比较好</p>
<h2 id="导入模块"><a class="markdownIt-Anchor" href="#导入模块"></a> 导入模块</h2>
<ol>
<li>pandas处理csv文件数据</li>
<li>random是因为原数据有上万条，为了保证样本随机，所以使用此模块随机抽取5000个数据</li>
<li>train_test_split将训练集中70%分为训练集，30%分为测试集</li>
<li>radians是将度数转换为弧度，比如90°转换成pai/2</li>
<li>re将数据中的字符串进行特征提取</li>
<li>SimpleImputer将数据中的空值进行填充，可以是object类型的数据，可按照平均值和众数进行填充，对于连续型数据，一般按照平均值填充，对于离散型，用众数填充</li>
<li>OrdinalEncoder，将object类型的数据进行编码，这样机器学习算法就能处理</li>
<li>StandardScaler，数据标准化，对数据进行无量纲化，避免有些特征对结果影响较大</li>
</ol>
<pre class="highlight"><code class="">import pandas as pd
import random
from sklearn.model_selection import train_test_split
from math import radians
import re
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OrdinalEncoder
from sklearn.preprocessing import StandardScaler
</code></pre>
<h2 id="读取数据"><a class="markdownIt-Anchor" href="#读取数据"></a> 读取数据</h2>
<ol>
<li>读取数据并查看是否有缺失值</li>
<li>info()函数可以观察数据的缺失值，和数据类型，object类型的数据一般是字符串类型的，通常是离散型</li>
</ol>
<p>输入：</p>
<pre class="highlight"><code class="">train = pd.read_csv(r'C:\Users\asus\Desktop\weatherAUS.csv')
# train.info()
</code></pre>
<p>输出：可以看到原始数据有上万条</p>
<pre class="highlight"><code class="">
&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 142193 entries, 0 to 142192
Data columns (total 24 columns):
Date             142193 non-null object
Location         142193 non-null object
MinTemp          141556 non-null float64
MaxTemp          141871 non-null float64
memory usage: 26.0+ MB

</code></pre>
<h2 id="删除数据"><a class="markdownIt-Anchor" href="#删除数据"></a> 删除数据</h2>
<ul>
<li>
<p>原数据集过大，处理起来相当麻烦，这里只保留前5000行数据</p>
</li>
<li>
<p>sample可以生成范围内，无重复的整数，k表示指定生成多少个数据</p>
</li>
<li>
<p>seed可以保证随机的取值都是一样的</p>
</li>
<li>
<p>使用drop()可以删除某一列特征，inplace参数为True，则改变原来的值，否则不会影响</p>
</li>
</ul>
<pre class="highlight"><code class=""># 原文件说必须把这个特征删除，否者会影响预测的准确率
train.drop(['RISK_MM'], axis=1, inplace=True)
random.seed(1)
stay = random.sample(range(train.shape[0]), k=5000)
</code></pre>
<h2 id="将标签和特征分离"><a class="markdownIt-Anchor" href="#将标签和特征分离"></a> 将标签和特征分离</h2>
<pre class="highlight"><code class="">x = train.iloc[stay,:-1]
y = train.iloc[stay,-1]
</code></pre>
<h2 id="拆分训练集和测试集"><a class="markdownIt-Anchor" href="#拆分训练集和测试集"></a> 拆分训练集和测试集</h2>
<ul>
<li>测试集占总数据的30%</li>
</ul>
<pre class="highlight"><code class="">x_train,x_test,y_train,y_test = train_test_split(x, y,random_state=0 ,test_size=0.3)
</code></pre>
<h2 id="重新设置index"><a class="markdownIt-Anchor" href="#重新设置index"></a> 重新设置index</h2>
<ul>
<li>由于测试集和训练集是随机的，所以index会混乱</li>
<li>重新设置index</li>
<li>这里不建议这样for循环，可以看看<strong>笔记python误区</strong></li>
</ul>
<pre class="highlight"><code class="">for each in [x_train,x_test,y_train,y_test]:
    each.index = range(each.shape[0])
</code></pre>
<h2 id="查看数据缺失率"><a class="markdownIt-Anchor" href="#查看数据缺失率"></a> 查看数据缺失率</h2>
<pre class="highlight"><code class=""># 查看缺失率，准备开始填充数据
# isnull返回一些列的true和false，mean用false/sum就是缺失率
x.isnull().mean()
</code></pre>
<h2 id="查看标签种类的出现次数"><a class="markdownIt-Anchor" href="#查看标签种类的出现次数"></a> 查看标签种类的出现次数</h2>
<p><strong>明天是否会下雨，可能会有标签为[是，不是，未知]，我们不可能光凭肉眼去看，粗略一看好像只有两个，这里使用unique(),这里只能使用Series.unique()</strong></p>
<ul>
<li>观察标签是object类型，将标签数值化</li>
<li>使用map()函数,进行映射</li>
</ul>
<pre class="highlight"><code class="">y.unique() #unique统计分类结果如['yes','no']
dict1 = {'No':0, 'Yes':1}
y = y.map(dict1)
</code></pre>
<h1 id="日期数据处理难"><a class="markdownIt-Anchor" href="#日期数据处理难"></a> 日期数据处理(难)</h1>
<ul>
<li><strong>对时间数据的处理思路</strong></li>
</ul>
<p>观察时间数据的特征<code>2009-10-30</code>，可以发现是字符串类型的，我们如何让时间对结果有影响呢？<strong>时间中有个很重要的数据</strong>，<strong>就是月份</strong>，我们知道，在不同的时间，下雨的可能性不一样，春天下雨可能性更大，而数据是字符串，所以我们可以用split或者正则表达式，对数据进行提取，获取月份，并转化成整型</p>
<h2 id="统计元素出现的次数"><a class="markdownIt-Anchor" href="#统计元素出现的次数"></a> 统计元素出现的次数</h2>
<ul>
<li>观察日期这个标签，如何转换日期呢？日期会不会有重复，因为不同地点，可能日期是一样的,使用Series的value_counts()函数，统计出现的次数，相当于Counter模块的Counter函数</li>
</ul>
<p>输入：</p>
<pre class="highlight"><code class="">x_train.Date.value_counts()
</code></pre>
<p>输出：</p>
<pre class="highlight"><code class="">2009-10-30    6
2015-03-13    6
2016-03-04    6
2015-06-01    5
2016-02-13    5
             ..
2014-04-30    1
2012-03-27    1
2011-02-23    1
2012-05-25    1
2016-12-20    1

</code></pre>
<h2 id="统计元素个数无重复"><a class="markdownIt-Anchor" href="#统计元素个数无重复"></a> 统计元素个数(无重复)</h2>
<ul>
<li>unique是统计多少个元素，并显示出具体元素名出来</li>
<li>nunique是显示元素的个数，只显示数字<br />
输入：</li>
</ul>
<pre class="highlight"><code class=""># 我们要去除重复的日期，观察有多少不同的日期
# 发现5000个数据中有2160个不同的时间
x_train.Date.nunique()
</code></pre>
<p>输出：</p>
<pre class="highlight"><code class="">2160
</code></pre>
<h2 id="对元素进行排序"><a class="markdownIt-Anchor" href="#对元素进行排序"></a> 对元素进行排序</h2>
<ul>
<li>这里对标签Location进行排序，会按地理位置A开始的显示</li>
<li>sort_values表示进行排序，这里<strong>按字母顺序排序</strong>，就可以看到同一地点的不同日期了</li>
</ul>
<pre class="highlight"><code class=""># 要知道时间数据是非常重要的，今天的天气可能会对明天的天气有影响

x_train.sort_values(by='Location')
</code></pre>
<pre class="highlight"><code class=""># 处理时间
# 观察相同时间的数据情况
# 可以发现，同一时间，都是不同地方的
result = x_train.loc[:,'Date'] == '2013-01-17'	
x_train.loc[result,:]
</code></pre>
<h2 id="提取时间中的月份"><a class="markdownIt-Anchor" href="#提取时间中的月份"></a> 提取时间中的月份</h2>
<ul>
<li>这里不建议用for循环，同时处理训练集和测试集</li>
<li>使用Series的apply方法，会自动将每一行进行循环，执行后面的函数，apply会取出Series的每一行元素，放入到后面的函数的x当中</li>
<li>由于apply后不会改变原始的数据，所以这里要进行赋值</li>
</ul>
<pre class="highlight"><code class="">for i in [x_train, x_test]:
    i.loc[:,&quot;Date&quot;] = i.loc[ :,&quot;Date&quot;].apply(lambda x:int(x.split('-')[1]))
</code></pre>
<h2 id="给date标签重新命名"><a class="markdownIt-Anchor" href="#给date标签重新命名"></a> 给Date标签重新命名</h2>
<ul>
<li>前面我们已经将月份提取出来了，所以可以将Date转换成Month</li>
<li>使用rename方法，传入将columns(列标签)重新命名</li>
</ul>
<pre class="highlight"><code class="">for i in [x_train, x_test]:
    i.rename(columns={'Date':'Month'}, inplace=True)
</code></pre>
<h1 id="地点数据处理"><a class="markdownIt-Anchor" href="#地点数据处理"></a> 地点数据处理</h1>
<p><strong>我们知道，一个国家，不同地区的地理气候是不一样的，原始数据向我们提供了气象站的名称，所以可以查到气象站的经纬度，同时，我们可以查到澳大利亚的城市名称，和澳大利亚气象局公布的，地理气候，上面归纳了每个城市的不同气候类型，发现一共只有8种气候类型，刚好可以设置成离散型数据，我们如果获取了气象站的坐标和澳大利亚城市的坐标，那么就可以根据公式来计算距离，气象站离哪个城市近，则气候就属于那个城市的气候</strong></p>
<p><a href="https://zhuanlan.zhihu.com/p/42948839" target="_blank" rel="noopener">这是地理公式</a></p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cwidehat%7BAB%7D+%3D+R+%5Ccdot+%5Carccos+%5Cbig%28+%5Ccos%28A_w%29+%5Ccos%28B_w%29+%5Ccos%28B_j-A_j%29+%2B%5Csin%28A_w%29+%5Csin%28B_w%29+%5Cbig%29" srcset="/img/loading.gif" alt="" /><br />
<em>w</em>表示纬度，<em>j</em>表示经度，两者都要用弧度来表示</p>
<p><a href="https://www.cnblogs.com/juanjiang/archive/2019/05/30/10948849.html" target="_blank" rel="noopener">数据预处理的模块讲解</a></p>
<h2 id="查看城市数量"><a class="markdownIt-Anchor" href="#查看城市数量"></a> 查看城市数量</h2>
<ul>
<li>使用value_counts只会计算城市出现的次数</li>
</ul>
<pre class="highlight"><code class="">x_train.Location.value_counts()
</code></pre>
<pre class="highlight"><code class="">MelbourneAirport    81
PerthAirport        79
Cairns              78
Sydney              77
Richmond            77
Sale                77
Watsonia            76
</code></pre>
<ul>
<li>在后面加上count()就会计算出现多少个城市了</li>
</ul>
<pre class="highlight"><code class="">x_train.Location.value_counts().count()
</code></pre>
<pre class="highlight"><code class="">49
</code></pre>
<h2 id="地理位置数据的爬取和保存"><a class="markdownIt-Anchor" href="#地理位置数据的爬取和保存"></a> 地理位置数据的爬取和保存</h2>
<ul>
<li>先从网上找到澳大利亚的城市名称，然后保存到txt文件中</li>
</ul>
<pre class="highlight"><code class="">from selenium import webdriver
import re
import pandas as pd
import time
</code></pre>
<ul>
<li>time模块是防止网速不好，网页数据没有加载出来</li>
<li>这里城市名保存在txt文件中，用read_table读取txt文件</li>
<li>将Series数据转换成列表</li>
<li>txt文件的读取要用read_table</li>
</ul>
<p><strong>txt中的数据如下：</strong></p>
<pre class="highlight"><code class="">5	Adelaide	South Australia	1,345,777	1,262,940	+6.56%	5.38%
43	Albany	Western Australia	34,205	30,656	+11.58%	0.14%
19	Albury–Wodonga	New South Wales/Victoria	93,603	82,083
</code></pre>
<p><strong>读取完毕后，不加参数header=None,则hi吧第一行，作为标签，我的原始数据是没有标签的，如年龄，性别等</strong></p>
<pre class="highlight"><code class=""># 读取txt文件要用read_table
# header=None，不会将第一行作为标签
data = pd.read_table(r'C:\Users\asus\Desktop\city.txt', header=None)
city = data.iloc[:,1].tolist()

# city = pd.read_csv(r'C:\Users\asus\Desktop\weatherAUS.csv')
# city.Location.unique().tolist()
# city.Location.nunique() 查看数据中提供了多少气象站
# 气象站是没用的，还需要获取城市的经度纬度

</code></pre>
<ul>
<li>这里创建一个新的DataFrame，将爬取的数据，一个个填入DF中</li>
<li>设置好标签和属性名，默认值是NaN</li>
</ul>
<pre class="highlight"><code class="">city_data = pd.DataFrame(index=range(len(city)), columns=['City','Latitude','Longitude'])
</code></pre>
<p><strong>爬取数据并保存</strong></p>
<pre class="highlight"><code class=""># 实例化对象
driver = webdriver.Chrome()
# 为了方便保存，我们获取城市序号和城市名
for num, each_city in enumerate(city):
    driver.get(r'https://www.latlong.net/place/sydney-nsw-australia-700.html')
    time.sleep(1)
    driver.find_element_by_id('keyword').send_keys(each_city)
    time.sleep(1)
    driver.find_element_by_xpath('//*[@id=&quot;frmsearch&quot;]/button').click()
    # 获取网页源代码
    page = driver.page_source
    r1 = re.compile('&lt;td&gt;(.*?)&lt;/td&gt;')
    result = re.findall(r1, page)
    # 开始保存数据，防止出错，加入异常处理
    try:
        city_data.loc[num,'City'] = each_city
        city_data.loc[num,'Latitude'] = result[1]
        city_data.loc[num,'Longitude'] = result[2]
    except:
        continue
    time.sleep(1)
city_data

# 查看爬取数据的缺失值
city_data.info()
</code></pre>
<h2 id="处理爬取的数据"><a class="markdownIt-Anchor" href="#处理爬取的数据"></a> 处理爬取的数据</h2>
<ol>
<li>city_climate保存的是，澳大利亚城市的气候</li>
<li>city_location，澳大利亚城市的坐标</li>
<li>sample_city，气象站的坐标</li>
</ol>
<pre class="highlight"><code class="">city_climate = pd.read_csv(r'C:\Users\asus\Desktop\Cityclimate.csv')
city_location = pd.read_csv(r'C:\Users\asus\Desktop\cityll.csv')
sample_city = pd.read_csv(r'C:\Users\asus\Desktop\samplecity.csv')
</code></pre>
<ul>
<li>这里不建议用这种for循环处理</li>
<li>由于爬取的数据是字符串类型的，要将地理位置坐标转换成浮点型，字符串后面有个°，所以可以采用切片的方式去掉</li>
</ul>
<pre class="highlight"><code class="">for each in [city_location, sample_city]:
    each.loc[:,'Longitude'] = each.loc[:,'Longitude'].apply(lambda x:float(x[:-1]))
    each.loc[:,'Latitude'] = each.loc[:,'Latitude'].apply(lambda x:float(x[:-1]))
    
</code></pre>
<ul>
<li>去除其他没用的属性，只保留城市名，经度，纬度，三个标签</li>
</ul>
<pre class="highlight"><code class="">city_location, sample_city = city_location.iloc[:,[1,2,3]],\
    sample_city.iloc[:,[1,2,3]]
</code></pre>
<p><strong>数据的合并</strong>(难点)</p>
<p>上面我们分别搜集了城市的坐标，和城市的气候，发现两列数据中列标签中city是一样的，所以可以将两个数据合并，使用merge方法，主要是左右合并</p>
<pre class="highlight"><code class=""># 发现两个文件的City标签是一样的，所以使用merge进行合并
# on属性可以指定依据什么标签合并，这样只会有一个city属性
city_location = pd.merge(city_location,city_climate,on='City'
</code></pre>
<p><strong>接下来，我们将计算气象站与城市的距离</strong></p>
<ul>
<li>loc方法，会自动创建新的属性</li>
<li>这里我们创建城市的经度，纬度标签，和气象站的经度纬度标签，只需要使用apply方法，radians是将度数转换成弧度的函数，使用apply后返回的是一个Sereis序列</li>
</ul>
<pre class="highlight"><code class=""># aw表示a点的纬度，aj表示a点的经度
# a点表示城市，b表示气象站
# 处理前要将角度转换成弧度，地理位置是角度，带公式要带弧度就是除以180°

city_location.loc[:,'aw'] = city_location.loc[:,'Latitude'].apply(lambda x:radians(x))
city_location.loc[:,'aj'] = city_location.loc[:,'Longitude'].apply(lambda x:radians(x))
sample_city.loc[:,'aw'] = sample_city.loc[:,'Latitude'].apply(lambda x:radians(x))
sample_city.loc[:,'aj'] = sample_city.loc[:,'Longitude'].apply(lambda x:radians(x))
</code></pre>
<p><strong>计算距离</strong></p>
<ul>
<li>我们要计算每个气象站，距离每个城市的距离，然后挑出距离最近的那个城市的标签，获得对应的气候</li>
<li>联系到KNN，array数据的特征，来进行计算</li>
<li>我们使用一个数据，减一列数据，计算出来地距离，同样是array类型，然后可以用np.argmin获得距离最小地坐标，再回带到DataFrame中，就找到了对应的气候</li>
</ul>
<pre class="highlight"><code class=""># np.array数据,能一个行向量减一个矩阵
# 而我们要用到计算每个气象站到每个城市的距离,直接for循环不方便
# 所以这里利用numpy数据的特点计算
R = 6378.13
for i in range(sample_city.shape[0]):# sample是气象站的个数
    # 气象站一个一个取
    bw = np.array(sample_city.loc[i,'Latitude'])
    bj = np.array(sample_city.loc[i,'Longitude'])
    # 城市则一列一列地取
    aw = np.array(city_location.loc[:,'Latitude'])
    aj = np.array(city_location.loc[:,'Longitude'])
    # 利用np,array数据的特征进行数据处理
    distance = R*np.arccos(np.cos(aw)*np.cos(bw)*np.cos(bj-aj)+np.sin(aw)*np.sin(bw))
    # 获得距离的最小值标签
    index = np.argmin(distance)
    # 根据标签得到最近的城市,和城市对应的天气
    sample_city.loc[i,'Closest_city'] = city_location.loc[index,'City']
    sample_city.loc[i,'Climate'] = city_location.loc[index,'Climate']
</code></pre>
<p><strong>我们已经找到每个气象站对应的气候了，但是抽取的5000个数据，还没有处理，如何将50个气象站的气候，对应到5000个训练集的气候呢？使用map函数，进行映射(难点)</strong></p>
<ul>
<li>只取出两个属性</li>
<li>并将气象站的名字，作为index，这样DateFrame中的数据只剩下气候了</li>
</ul>
<pre class="highlight"><code class="">final_climate = sample_city.loc[:,['City','Climate']]
final_climate = final_climate.set_index(keys='City')
</code></pre>
<ul>
<li>之前我们使用map函数就是将标签传入字典，Yes：1，No：0</li>
<li>其实map还可以传入Series类型的，故需要从DF中取出一列</li>
<li>对训练集和测试集一起操作，将气象站，改成气候，并没有保留气象站的名字</li>
</ul>
<pre class="highlight"><code class=""># map函数可以形成映射的关系,可以传入字典或者Series,Sereis的index必须是字典的键
x_train['Location'] = x_train['Location'].map(final_climate['Climate'])
x_test['Location'] = x_test['Location'].map(final_climate['Climate'])
</code></pre>
<p><strong>给city重新命名</strong></p>
<p>我们已将气象站变成了气候，进行重新命名</p>
<pre class="highlight"><code class=""># 给特征重新命名
# 直接这样rename不会改变原来的值
x_train = x_train.rename(columns={'Location':'Climate'})
x_test = x_test.rename(columns={'Location':'Climate'})
</code></pre>
<h1 id="数据转换重要"><a class="markdownIt-Anchor" href="#数据转换重要"></a> 数据转换(重要)</h1>
<p><a href="https://blog.csdn.net/weixin_41798592/article/details/101344948" target="_blank" rel="noopener">详细请看</a></p>
<ul>
<li>由于上面爬取的城市气候数据中，气候名夹杂着空格和逗号，机器学习不擅长处理这些数据，所以要用正则替换为空</li>
</ul>
<pre class="highlight"><code class=""># 将climate中的空格和逗号都去除,使用正则表达式
# apply不会改变原来的Seriers的值
x_train.loc[:,'Climate'] = x_train.loc[:,'Climate'].apply(lambda x:re.sub(' ','',x))
x_train.loc[:,'Climate'] = x_train.loc[:,'Climate'].apply(lambda x:re.sub(',','',x))
x_test.Climate = x_test.Climate.apply(lambda x:re.sub(&quot; &quot;,'',x))
x_test.Climate = x_test.Climate.apply(lambda x:re.sub(',','',x))
</code></pre>
<h2 id="缺失值的填充"><a class="markdownIt-Anchor" href="#缺失值的填充"></a> 缺失值的填充</h2>
<ol>
<li>连续型用均值填充，离散型，用众数进行填充</li>
<li>连续型变量，要做标准化处理，分类型变量不用标准化</li>
</ol>
<h3 id="离散型数据的填补"><a class="markdownIt-Anchor" href="#离散型数据的填补"></a> 离散型数据的填补</h3>
<p><strong>将离散型数据和连续型数据分开处理</strong></p>
<ul>
<li>查看数据类型，object类，一般是离散型数据</li>
</ul>
<pre class="highlight"><code class="">x_train.dtypes
</code></pre>
<pre class="highlight"><code class="">Month              int64
Location          object
MinTemp          float64
MaxTemp          float64

</code></pre>
<ul>
<li>取出为object类型的数据</li>
</ul>
<p>输入：</p>
<pre class="highlight"><code class="">x_train.dtypes == object
</code></pre>
<p>返回的是布尔类型</p>
<pre class="highlight"><code class="">Month            False
Location          True
MinTemp          False
MaxTemp          False
</code></pre>
<p>输入：</p>
<pre class="highlight"><code class=""># 取出类型为object的标签，等待转换成数值型
object_columns = x_train.loc[:,x_train.dtypes == object].columns.tolist()

# 除了字符串类型的属于离散型，我们还可以看到有些数字型也算离散变量
object_columns.extend(['Cloud9am','Cloud3pm'])
discrete_columns = object_columns
</code></pre>
<p>输出：</p>
<pre class="highlight"><code class="">['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm
</code></pre>
<p>查看离散型数据的缺失情况</p>
<pre class="highlight"><code class=""># 开始进行数据转换
# 先查看数据的缺失情况
x_train.loc[:,object_columns].isnull().mean()
</code></pre>
<p><strong>导入模块，开始填补</strong></p>
<ul>
<li>使用的是SimpleImputer模块</li>
<li>先实例化，对缺失值为nan的数据，以频率最高的进行填补</li>
</ul>
<pre class="highlight"><code class=""># 先导入模块，然后实例化
si = SimpleImputer(missing_values=np.nan, strategy='most_frequent')
</code></pre>
<ul>
<li>数据分为训练集和测试集，我们对测试集中的缺失值进行处理，用的是训练集中的众数进行填充，因为训练集的数据，特征肯定是更具有一般性的</li>
<li>这里不用fit_transform一步到位，就是因为，对训练集和测试集的填充</li>
<li>fit相当于得到众数，transform相当于开始对对象进行填充</li>
</ul>
<pre class="highlight"><code class="">si.fit(x_train.loc[:,discrete_columns]) # 相当于求出最高频率的
# 开始对空值进行填充
x_train.loc[:,discrete_columns] = si.transform(x_train.loc[:,discrete_columns])
x_test.loc[:,discrete_columns] = si.transform(x_test.loc[:,discrete_columns])
</code></pre>
<p><strong>查看填充情况</strong></p>
<pre class="highlight"><code class=""># 发现离散型数据空值都已经填充好了
x_train.loc[:,discrete_columns].isnull().mean()
</code></pre>
<ul>
<li>都为0表示填充完毕</li>
</ul>
<pre class="highlight"><code class="">Climate        0.0
WindGustDir    0.0
WindDir9am     0.0
WindDir3pm     0.0
RainToday      0.0
Cloud9am       0.0
Cloud3pm       0.0

</code></pre>
<h3 id="连续型数据的填补"><a class="markdownIt-Anchor" href="#连续型数据的填补"></a> 连续型数据的填补</h3>
<ul>
<li>上面我们得到了离散型变量的名字，所以除掉这些，剩下的就是连续的了</li>
</ul>
<pre class="highlight"><code class=""># 开始对连续型数据进行缺失值的填补
# 只需要对不是离散的处理就行了
continues = []
for each in x_train.columns:
    if each not in discrete_columns:
        continues.append(each)
</code></pre>
<ul>
<li>同样是使用SimpleImputer进行填充，填充方法是平均值</li>
</ul>
<pre class="highlight"><code class="">si = SimpleImputer(missing_values=np.nan, strategy='mean')
x_train.loc[:,continues] = si.fit_transform(x_train.loc[:,continues])
x_test.loc[:,continues] = si.fit_transform(x_test.loc[:,continues])
</code></pre>
<ul>
<li>都要导入skleran.preprocessing</li>
</ul>
<h2 id="将标签转换成数值型lableencoder"><a class="markdownIt-Anchor" href="#将标签转换成数值型lableencoder"></a> 将标签转换成数值型LableEncoder</h2>
<ul>
<li>preprocessing.LabelEncoder：标签专用，能够将分类转换为分类数值</li>
</ul>
<h2 id="将离散分类型数据转换成数值型"><a class="markdownIt-Anchor" href="#将离散分类型数据转换成数值型"></a> 将离散分类型数据转换成数值型</h2>
<p><strong>前面我们已经对离散型数据和连续型数据填充完毕，由于离散型数据大多数是字符串类型的，所以要将字符串类型，转变成数值型</strong></p>
<ul>
<li>
<p>其实就相当于将male编号成0，将female编号成1，只不过现在用模块来处理</p>
</li>
<li>
<p>训练集和测试集，都有离散值，所以都要进行处理</p>
</li>
<li>
<p>preprocessing.OrdinalEncoder：特征专用，能够将分类特征转换为分类数值</p>
</li>
</ul>
<pre class="highlight"><code class=""># 离散型数据缺失值填充好了，开始对离散型数据进行编码，转换成数字类型
# 依旧是使用fit_transform进行转换
encode = OrdinalEncoder()
x_train.loc[:,discrete_columns] = encode.fit_transform(x_train.loc[:,discrete_columns])
x_test.loc[:,discrete_columns] = encode.fit_transform(x_test.loc[:,discrete_columns])
</code></pre>
<h2 id="数据无量纲化"><a class="markdownIt-Anchor" href="#数据无量纲化"></a> 数据无量纲化</h2>
<ul>
<li>无量纲化，这里只针对连续型变量，离散型如0-1，无量纲化是没意义的</li>
</ul>
<pre class="highlight"><code class=""># 数据的无量纲化
# 这里无量纲化只对连续型数据进行，不考虑分类型数据的
continues.remove('Month')
</code></pre>
<ul>
<li>使用sklearn.preprocessing中的StandardScaler模块</li>
<li>开始对连续型变量进行无量纲化，这里采用的是标准化处理</li>
</ul>
<pre class="highlight"><code class=""># 使用StandardScaler进行无量纲化
s = StandardScaler()
x_train.loc[:,continues] = s.fit_transform(x_train.loc[:,continues])
x_test.loc[:,continues] = s.fit_transform(x_test.loc[:,continues])
</code></pre>
<h1 id="精确度和召回率"><a class="markdownIt-Anchor" href="#精确度和召回率"></a> 精确度和召回率</h1>
<h2 id="精确度"><a class="markdownIt-Anchor" href="#精确度"></a> 精确度</h2>
<ul>
<li>指所有判断正确，并真实值为1的点/所有判断为1的点</li>
</ul>
<blockquote>
<p>精确度越高，说明判断错误的点越少，对正确点a的捕捉能力强</p>
</blockquote>
<h2 id="召回率"><a class="markdownIt-Anchor" href="#召回率"></a> 召回率</h2>
<ul>
<li>所有预测为1的点/真实值为1的点</li>
</ul>
<blockquote>
<p>召回率表示预测正确的样本所占的比例,召回率越高，说明判断正确的点越多，但是判断错误的点，也可能很多</p>
</blockquote>
<ul>
<li>例如当在分析是否为潜在犯罪问题的时候，我们就需要召回率高，另可错杀一千，也不愿放过一个</li>
</ul>
<blockquote>
<p>精确度上来了，召回率就会下去</p>
</blockquote>
<p>在本项目中，如果我们提高准确度，那么召回率就会下降，假如现在判断某一天会不会下雨</p>
<p>召回率越高，说明，虽然我判断明天可能会下雨，<strong>实际上明天是晴天</strong>，但能保证，判断明天会下雨的天，一定包含在我预测的天数里(夸张点说，我预测今年一定会下雨)</p>
<p>精确度越高，就是我预测这些天会下雨，确实，这些天很多都下雨了，<strong>但在我预测之外，仍然有些天会下雨我没预测到</strong></p>
<h1 id="模型预测"><a class="markdownIt-Anchor" href="#模型预测"></a> 模型预测</h1>
<p>数据处理完毕后，使用sklearn中的机器学习方法，开始对天气进行预测</p>
<h2 id="导入模块-2"><a class="markdownIt-Anchor" href="#导入模块-2"></a> 导入模块</h2>
<pre class="highlight"><code class="">from sklearn.svm import SVC
from sklearn.metrics import recall_score
</code></pre>
<ul>
<li>ravel是将二维数组，降维</li>
<li>另外，reshape(-1)也可以“拉平”多维数组</li>
</ul>
<pre class="highlight"><code class="">d = {'Yes':1,'No':0}
# 这里y_test，y_train是Series类型的数据，所以要将他们转换成DF数据，才能使用map
y_test, y_train = pd.DataFrame(y_test), pd.DataFrame(y_train)
y_test, y_train = y_test.iloc[:,0].map(d).ravel(),\
    y_train.iloc[:,0].map(d).ravel()
</code></pre>
<p><img src="https://upload-images.jianshu.io/upload_images/13780430-65c7e9c3d8798198.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp" srcset="/img/loading.gif" alt="" /></p>
<p><strong>选取核函数，先挑选出最好的核函数，再进一步调节参数</strong></p>
<pre class="highlight"><code class="">for kernel in ['linear','poly','rbf','sigmoid']:
    clf = SVC(kernel = kernel, gamma = 'auto', degree = 1, cache_size = 2500)
    clf = clf.fit(x_train, y_train)
    result = clf.predict(x_test)
    score = clf.score(x_test, y_test)
    recall = recall_score(y_test, result)
    print(f'核函数：{kernel},精确度：{score},召回率{recall}')
</code></pre>
<ul>
<li>我们可以看到，四种核函数中，ploy 和 linear 核函数是最佳的</li>
</ul>
<pre class="highlight"><code class="">核函数：linear,精确度：0.8453333333333334,召回率0.4852941176470588
核函数：poly,精确度：0.8466666666666667,召回率0.4764705882352941
核函数：rbf,精确度：0.8206666666666667,召回率0.3323529411764706
核函数：sigmoid,精确度：0.636,召回率0.1323529411764706
</code></pre>
<h1 id="调节参数优化模型"><a class="markdownIt-Anchor" href="#调节参数优化模型"></a> 调节参数，优化模型</h1>
<p><a href="https://blog.csdn.net/gracejpw/article/details/103054668" target="_blank" rel="noopener">参考自CSDN</a></p>
<h2 id="不均衡问题"><a class="markdownIt-Anchor" href="#不均衡问题"></a> 不均衡问题</h2>
<p>对于分类问题，永远都逃不过的一个痛点就是样本不均衡问题。样本不均衡是指在一组数据集中，标签的一类天生占有很大的比例，但我们有着捕捉出某种特定的分类的需求的状况。比如，我们现在要对潜在犯罪者和普通人进行分类，潜在犯罪者占总人口的比例是相当低的，也许只有2%左右，98%的人都是普通人，而我们的目标是要捕获出潜在犯罪者。这样的标签分布会带来许多问题。</p>
<p>首先，分类模型天生会倾向于多数的类，让多数类更容易被判断正确，少数类被牺牲掉。因为对于模型而言，样本量越大的标签可以学习的信息越多，算法就会更加依赖于从多数类中学到的信息来进行判断。如果我们希望捕获少数类，模型就会失败。其次，模型评估指标会失去意义。这种分类状况下，即便模型什么也不做，全把所有人都当成不会犯罪的人，准确率也能非常高，这使得模型评估指标accuracy变得毫无意义，根本无法达到我们的“要识别出会犯罪的人”的建模目的</p>
<p>所以现在，我们首先要让算法意识到数据的标签是不均衡的，通过施加一些惩罚或者改变样本本身，来让模型向着捕获少数类的方向建模。然后，我们要改进我们的模型评估指标，使用更加针对于少数类的指标来优化模型。<br />
要解决第一个问题，可以采用上采样下采样的方法。但这些采样方法会增加样本的总数，对于支持向量机这个样本总是对计算速度影响巨大的算法来说，我们完全不想轻易地增加样本数量。况且，支持向量机中的决策仅仅受决策边界的影响，而决策边界又仅仅受到参数C和支持向量的影响，单纯地增加样本数量不仅会增加计算时间，可能还会增加无数对决策边界无影响的样本点。因此在支持向量机中，我们要大力依赖我们调节样本均衡的参数：SVC类中的class_weight和接口fit中可以设定的sample_weight。</p>
<p>在逻辑回归中，参数class_weight默认None，此模式表示假设数据集中的所有标签是均衡的，即自动认为标签的比例是1：1。所以当样本不均衡的时候，我们可以使用形如{“标签的值1”：权重1，“标签的值2”：权重2}的字典来输入真实的样本标签比例，来让算法意识到样本是不平衡的。</p>
<p>但在SVM中，我们的分类判断是基于决策边界的，而最终决定究竟使用怎样的支持向量和决策边界的参数是参数C，所以所有的样本均衡都是通过参数C来调整的。</p>
<pre class="highlight"><code class="">class_1 = 500 #类别1有500个样本
class_2 = 50 #类别2只有50个

#不设定class_weight
clf = SVC(kernel='linear', C=1.0)
clf.fit(X, y)
#设定class_weight
wclf = SVC(kernel='linear', class_weight={1: 10})
wclf.fit(X, y)
#给两个模型分别打分看看，这个分数是accuracy准确度
clf.score(X,y)
</code></pre>
<p>可以看出，从准确率的角度来看，不做样本平衡的时候准确率反而更高，做了样本平衡准确率反而变低了，这是因为做了样本平衡后，为了要更有效地捕捉出少数类，模型误伤了许多多数类样本，而多数类被分错的样本数量 &gt; 少数类被分类正确的样本数量，使得模型整体的精确性下降。现在，如果我们的目的是模型整体的准确率，那我们就要拒绝样本平衡，使class_weight被设置之前的模型。</p>
<p>然而在现实中，我们往往都在追求捕捉少数类，因为在很多情况下，将少数类判断错的代价是巨大的。比如我们之前提到的，判断潜在犯罪者和普通人的例子，如果我们没有能够识别出潜在犯罪者，那么这些人就可能去危害社会，造成恶劣影响，但如果我们把普通人错认为是潜在犯罪者，我们也许只是需要增加一些监控和人为甄别的成本。所以对我们来说，我们宁愿把普通人判错，也不想放过任何一个潜在犯罪者。我们希望不惜一切代价来捕获少数类，或者希望捕捉出尽量多的少数类，那我们就必须使用class_weight设置后的模型。</p>

            <hr>
          </div>
          <br>
          <div>
            <p>
            
              <span>
                <i class="iconfont icon-inbox"></i>
                
                  <a class="hover-with-bg" href="/categories/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98">项目实战</a>
                  &nbsp;
                
              </span>&nbsp;&nbsp;
            
            
              <span>
                <i class="iconfont icon-tag"></i>
                
                  <a class="hover-with-bg" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">机器学习</a>
                
              </span>
            
            </p>
            
              <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://zh.wikipedia.org/wiki/Wikipedia:CC_BY-SA_3.0%E5%8D%8F%E8%AE%AE%E6%96%87%E6%9C%AC" target="_blank" rel="nofollow noopener noopener">CC BY-SA 3.0协议</a> 。转载请注明出处！</p>
            
          </div>
        </div>
      </div>
    </div>
    <div class="d-none d-lg-block col-lg-2 toc-container">
      
  <div id="toc">
    <p class="h5"><i class="far fa-list-alt"></i>&nbsp;目录</p>
    <div id="tocbot"></div>
  </div>

    </div>
  </div>
</div>

<!-- custom -->

  <div class="col-lg-7 mx-auto nopadding-md">
    <div class="container custom post-content mx-auto">
      <img src="https://octodex.github.com/images/jetpacktocat.png" class="rounded mx-auto d-block mt-5" style="width:150px; height:150px;">
    </div>
  </div>


<!-- Comments -->
<div class="col-lg-7 mx-auto nopadding-md">
  <div class="container comments mx-auto" id="comments">
    
  </div>
</div>

    
  </main>

  
    <a class="z-depth-1" id="scroll-top-button" href="#" role="button">
      <i class="fa fa-chevron-up scroll-top-arrow" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  <footer class="mt-5">
  <div class="text-center py-3">
    <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><b>Hexo</b></a>
    <i class="iconfont icon-love"></i>
    <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"> <b>Fluid</b></a>
    <br>

    
  
    <!-- 不蒜子统计PV -->
    
    &nbsp;<span id="busuanzi_container_site_pv"></span>总访问量 
          <span id="busuanzi_value_site_pv"></span> 次&nbsp;
  
  
    <!-- 不蒜子统计UV -->
    
    &nbsp;<span id="busuanzi_container_site_uv"></span>总访客数 
            <span id="busuanzi_value_site_uv"></span> 人&nbsp;
  
  <br>



    


    <!-- cnzz Analytics icon -->
    

  </div>
</footer>

<!-- SCRIPTS -->
<script src="/lib/jquery/jquery.min.js" ></script>
<script src="/lib/popper/popper.min.js" ></script>
<script src="/lib/bootstrap/js/bootstrap.min.js" ></script>
<script src="/lib/mdbootstrap/js/mdb.min.js" ></script>
<script src="/js/main.js" ></script>


  <script src="/js/lazyload.js" ></script>



  <script src="/js/post.js" ></script>
  
    <script src="/lib/tocbot/tocbot.min.js" ></script>
    <script>
      $(document).ready(function () {
        tocbot.init({
          tocSelector: '#tocbot',
          contentSelector: '.post-content',
          headingSelector: 'h1,h2,h3,h4,h5,h6',
          linkClass: 'tocbot-link',
          activeLinkClass: 'tocbot-active-link',
          listClass: 'tocbot-list',
          isCollapsedClass: 'tocbot-is-collapsed',
          collapsibleClass: 'tocbot-is-collapsible',
          scrollSmooth: true,
        });
      });
    </script>
  



  <script src="/lib/smoothscroll/SmoothScroll.min.js" ></script>



  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>


<!-- Plugins -->



  <script src="/lib/prettify/prettify.min.js" ></script>
  <script>
    $(document).ready(function () {
      $('pre').addClass('prettyprint  ');
      prettyPrint();
    })
  </script>



  <script src="/lib/typed/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "明天会下雨吗？&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script src="/lib/anchor/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script src="/lib/fancybox/jquery.fancybox.min.js" ></script>
  <script>
    $("#post img:not(.no-zoom img, img[no-zoom])").each(
      function () {
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "images");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      }
    );
  </script>



  

  
    <!-- MathJax -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
          tex2jax: {
              inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
              processEscapes: true,
              skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
          }
      });

      MathJax.Hub.Queue(function() {
          var all = MathJax.Hub.getAllJax(), i;
          for(i=0; i < all.length; i += 1) {
              all[i].SourceElement().parentNode.className += ' has-jax';
          }
      });

    </script>

    <script src="https://cdn.staticfile.org/mathjax/2.7.6/MathJax.js?config=TeX-MML-AM_CHTML" ></script>

  



  
  
    <script type="text/javascript">
      //定义获取词语下标
      var a_idx = 0;
      jQuery(document).ready(function ($) {
        //点击body时触发事件
        $("body").click(function (e) {
          //需要显示的词语
          var a = new Array("富强", "民主", "文明", "和谐", "自由", "平等", "公正", "法治", "爱国", "敬业", "诚信", "友善");
          //设置词语给span标签
          var $i = $("<span/>").text(a[a_idx]);
          //下标等于原来下标+1  余 词语总数
          a_idx = (a_idx + 1) % a.length;
          //获取鼠标指针的位置，分别相对于文档的左和右边缘。
          //获取x和y的指针坐标
          var x = e.pageX, y = e.pageY;
          //在鼠标的指针的位置给$i定义的span标签添加css样式
          $i.css({
            "z-index": 999,
            "top": y - 20,
            "left": x,
            "position": "absolute",
            "font-weight": "bold",
            "color": rand_color()
          });
          // 随机颜色
          function rand_color() {
            return "rgb(" + ~~(255 * Math.random()) + "," + ~~(255 * Math.random()) + "," + ~~(255 * Math.random()) + ")"
          }
          //在body添加这个标签
          $("body").append($i);
          //animate() 方法执行 CSS 属性集的自定义动画。
          //该方法通过CSS样式将元素从一个状态改变为另一个状态。CSS属性值是逐渐改变的，这样就可以创建动画效果。
          //详情请看http://www.w3school.com.cn/jquery/effect_animate.asp
          $i.animate({
            //将原来的位置向上移动180
            "top": y - 180,
            "opacity": 0
            //1500动画的速度
          }, 1500, function () {
            //时间到了自动删除
            $i.remove();
          });
        });
      })
      ;
    </script>
  








</body>
</html>
